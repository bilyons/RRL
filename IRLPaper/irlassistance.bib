@inproceedings{ng2000algorithms,
  title={Algorithms for inverse reinforcement learning.},
  author={Ng, Andrew Y and Russell, Stuart J and others},
  booktitle={Icml},
  volume={1},
  pages={2},
  year={2000}
}

@inproceedings{lyons2020relexive,
  title={Reflexive reinforcement learning: Reflexive reinforcement learning:
Methods for self-referential autonomous learning},
  author={Lyons, Billy and Herrmann, J. Michael},
  booktitle={NCTA},
  year={2020},
note={(accepted)}
}

@inproceedings{ziebart2008maximum,
  title={Maximum entropy inverse reinforcement learning},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K},
  booktitle={Aaai},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}

@article{finn2016connection,
  title={A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models},
  author={Finn, Chelsea and Christiano, Paul and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.03852},
  year={2016}
}

@article{sutton1999reinforcement,
  title={Reinforcement learning},
  author={Sutton, Richard S and Barto, Andrew G},
  journal={Journal of Cognitive Neuroscience},
  volume={11},
  number={1},
  pages={126--134},
  year={1999}
}

@book{bellman2013dynamic,
  title={Dynamic Programming},
  author={Bellman, R.},
  isbn={9780486317199},
  series={Dover Books on Computer Science},
  url={https://books.google.co.uk/books?id=CG7CAgAAQBAJ},
  year={2013},
  publisher={Dover Publications}
}
@article{campbell2002deep,
  title={Deep blue},
  author={Campbell, Murray and Hoane Jr, A Joseph and Hsu, Feng-hsiung},
  journal={Artificial intelligence},
  volume={134},
  number={1-2},
  pages={57--83},
  year={2002},
  publisher={Elsevier}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{\k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{andrychowicz2020learning,
  title={Learning dexterous in-hand manipulation},
  author={Andrychowicz, OpenAI: Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and others},
  journal={The International Journal of Robotics Research},
  volume={39},
  number={1},
  pages={3--20},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{morimoto2001acquisition,
  title={Acquisition of stand-up behavior by a real robot using hierarchical reinforcement learning},
  author={Morimoto, Jun and Doya, Kenji},
  journal={Robotics and Autonomous Systems},
  volume={36},
  number={1},
  pages={37--51},
  year={2001},
  publisher={Elsevier}
}

@article{asada1996purposive,
  title={Purposive behavior acquisition for a real robot by vision-based reinforcement learning},
  author={Asada, Minoru and Noda, Shoichi and Tawaratsumida, Sukoya and Hosoda, Koh},
  journal={Machine learning},
  volume={23},
  number={2},
  pages={279--303},
  year={1996},
  publisher={Springer}
}

@inproceedings{karnchanachari2020practical,
  title={Practical Reinforcement Learning For MPC: Learning from sparse objectives in under an hour on a real robot},
  author={Karnchanachari, Napat and Valls, Miguel Iglesia and Hoeller, David and Hutter, Marco},
  booktitle={Learning for Dynamics and Control},
  pages={211--224},
  year={2020},
  organization={PMLR}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@inproceedings{abbeel2004apprenticeship,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={1},
  year={2004}
}

@article{choi2011inverse,
  title={Inverse reinforcement learning in partially observable environments},
  author={Choi, JD and Kim, Kee-Eung},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={691--730},
  year={2011},
  publisher={MICROTOME PUBL}
}

@conference{ncta20,
author={B. Lyons. and J. Herrmann.},
title={Reflexive Reinforcement Learning: Methods for Self-Referential Autonomous Learning},
booktitle={Proceedings of the 12th International Joint Conference on Computational Intelligence - Volume 1: NCTA,},
year={2020},
pages={381-388},
publisher={SciTePress},
organization={INSTICC},
doi={10.5220/0009997503810388},
isbn={978-989-758-475-6},
}

@article{sutton1991integrated,
  title={Integrated modeling and control based on reinforcement learning and dynamic programming},
  author={Sutton, Richard S},
  journal={Advances in neural information processing systems},
  volume={3},
  pages={471--478},
  year={1991},
  publisher={Citeseer}
}
